{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook to accompany:\n",
    "\"Loop Flexibility Enables Remote Transduction of Energy into the Enolase Active Site\" by Emily J. Thompson, Adhayana Paul, Anthony T. Iavarone, and Judith P. Klinman\n",
    "\n",
    "\n",
    "Uploaded Sep 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from imp import reload as rl\n",
    "from glob import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "\n",
    "# settings\n",
    "## pandas\n",
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "## matplot\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing colors for the graphs\n",
    "# colors9 = blue --> grey --> red\n",
    "\n",
    "temps = ('10C', '20C', '25C', '30C', '40C')\n",
    "print(temps)\n",
    "\n",
    "colorset = [\"#0c2c84\", \"#1d91c0\", \"#74a9cf\", \"#bababa\", \"#fb6a4a\", \"#ef3b2c\", \"#b10026\"]\n",
    "CS = sns.color_palette(colorset)\n",
    "allblack = sns.color_palette(['black','black','black','black','black','black','black'])\n",
    "\n",
    "# print colors to see:\n",
    "sns.palplot(CS)\n",
    "sns.palplot(allblack)\n",
    "\n",
    "# temperature:color code for plotting:\n",
    "temp2color = {temp:color for temp, color in zip(temps, CS)}\n",
    "temp2colorblack = {temp:color for temp, color in zip(temps, colorblack)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pandas table from XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate back exchange file first from HDX Workbench XML output\n",
    "\n",
    "files = glob('XML_BE/*.xml')\n",
    "#print(files)\n",
    "\n",
    "BE = []\n",
    "\n",
    "for i in files:\n",
    "    tree = et.parse(i)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    df = {'start':[], 'end':[], 'charge':[], 'sequence':[], 'temperature':[], 'timepoint':[], 'replicate':[], 'percentD':[], 'valid':[]}\n",
    "\n",
    "    for peptide in root.iter('Peptide'):\n",
    "        for sample in peptide.getchildren():\n",
    "            for datapoint in sample.getchildren():\n",
    "                for rep in datapoint.getchildren():\n",
    "                    if len(peptide.attrib['start']) > 0:\n",
    "                        df['start'].append(peptide.attrib['start'])\n",
    "                    else:\n",
    "                        df['start'].append(np.nan)\n",
    "                    df['end'].append(float(peptide.attrib['end']))\n",
    "                    df['charge'].append(float(peptide.attrib['charge']))\n",
    "                    df['sequence'].append(peptide.attrib['sequence'])\n",
    "                    df['timepoint'].append(float(datapoint.attrib['name'].strip().replace('s','')))\n",
    "                    df['temperature'].append(sample.attrib['name'])\n",
    "                    df['replicate'].append(rep.attrib['name'])\n",
    "                    df['percentD'].append(float(rep.attrib['percentD']))\n",
    "                    df['valid'].append(rep.attrib['valid'])\n",
    "    BE.append(pd.DataFrame(df))\n",
    "\n",
    "BE = pd.concat(BE)\n",
    "BE['percentD_good'] = np.where(BE['valid']=='true', BE.percentD, np.NaN) \n",
    "BE['start'] = BE['start'].apply(float)\n",
    "BE.sort_values(['start','end','charge','temperature','timepoint','replicate'],inplace=True)\n",
    "BE.to_csv('XML_BE/BE.tsv', sep=\"\\t\")\n",
    "BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curate BE.tsv file to only contain designated peptide set.\n",
    "# Further datasets will be reduced to only contain peptides in the BE_df \n",
    "\n",
    "BE_df = pd.DataFrame(pd.read_csv('XML_BE/BE_curated.tsv', sep='\\t'))\n",
    "BE_df['start'] = BE_df['start'].apply(float)\n",
    "BE_df['charge'] = BE_df['charge'].apply(float)\n",
    "BE_df['end'] = BE_df['end'].apply(float)\n",
    "BE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all temperature dependent HDX-MS data from XML files and tabulate into dataframe\n",
    "# percentD_good reports on the HDX Workbench value that can be toggled to include or not include a data point\n",
    "\n",
    "files = glob('XML_data/*.xml')\n",
    "\n",
    "WT = []\n",
    "\n",
    "for i in files:\n",
    "    tree = et.parse(i)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    df = {'start':[], 'end':[], 'charge':[], 'sequence':[], 'temperature':[], 'timepoint':[], 'replicate':[], 'percentD':[], 'valid':[]}\n",
    "\n",
    "    for peptide in root.iter('Peptide'):\n",
    "        for sample in peptide.getchildren():\n",
    "            for datapoint in sample.getchildren():\n",
    "                for rep in datapoint.getchildren():\n",
    "                    if len(peptide.attrib['start']) > 0:\n",
    "                        df['start'].append(peptide.attrib['start'])\n",
    "                    else:\n",
    "                        df['start'].append(np.nan)\n",
    "                    df['end'].append(float(peptide.attrib['end']))\n",
    "                    df['charge'].append(float(peptide.attrib['charge']))\n",
    "                    df['sequence'].append(peptide.attrib['sequence'])\n",
    "                    df['timepoint'].append(float(datapoint.attrib['name'].strip().replace('s','')))\n",
    "                    df['temperature'].append(sample.attrib['name'])\n",
    "                    df['replicate'].append(rep.attrib['name'])\n",
    "                    df['percentD'].append(float(rep.attrib['percentD']))\n",
    "                    df['valid'].append(rep.attrib['valid'])\n",
    "    WT.append(pd.DataFrame(df))\n",
    "\n",
    "WT = pd.concat(WT)\n",
    "WT['percentD_good'] = np.where(WT['valid']=='true', WT.percentD, np.NaN) \n",
    "WT['start'] = WT['start'].apply(float)\n",
    "WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge BE and WT dataframes such that only peptides in the BE dataframe are used for further analysis\n",
    "# converting time point data from seconds into minutes\n",
    "\n",
    "\n",
    "merged = {}\n",
    "merged = pd.merge(left=BE_df, right=WT, on=['start', 'end', 'charge'])\n",
    "merged['percentD_corr']=merged['percentD_good']*100/merged['BE']\n",
    "merged['timepoint']=merged['timepoint'].astype(np.int64)\n",
    "merged['replicate']=merged['replicate'].astype(np.int64)\n",
    "merged['timepoint'] = (merged['timepoint'])/60\n",
    "merged['AAs']=merged['sequence'].str.len()\n",
    "merged['#P']=merged['sequence'].str.count('P')\n",
    "merged['NH-total']=merged['AAs']-merged['#P']-2\n",
    "merged['Daltons']=merged['percentD_corr']/100*merged['NH-total']\n",
    "merged.sort_values(['start','end','charge','temperature','timepoint','replicate'],inplace=True)\n",
    "\n",
    "merged.to_csv('merged.tsv', sep=\"\\t\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average and standard deviation of replicate data\n",
    "\n",
    "merged2 ={}\n",
    "merged2['start'] = []\n",
    "merged2['end'] = []\n",
    "merged2['charge'] = []\n",
    "merged2['temperature'] = []\n",
    "merged2['timepoint'] = []\n",
    "merged2['avg'] = []\n",
    "merged2['sd'] = []\n",
    "    \n",
    "esubs = ['charge', 'start', 'end', 'temperature', 'timepoint']\n",
    "for e, ee in merged.groupby(by = esubs):\n",
    "    avgv = ee['Daltons'].mean()\n",
    "    stdv = ee['Daltons'].std()\n",
    "    merged2['avg'].append(avgv)\n",
    "    merged2['sd'].append(stdv)\n",
    "    merged2['start'].append(ee['start'].iloc[0])\n",
    "    merged2['end'].append(ee['end'].iloc[0])\n",
    "    merged2['charge'].append(ee['charge'].iloc[0])\n",
    "    merged2['temperature'].append(ee['temperature'].iloc[0])\n",
    "    merged2['timepoint'].append(ee['timepoint'].iloc[0])\n",
    "merged2 = pd.DataFrame(merged2)\n",
    "merged2\n",
    "\n",
    "mergedc = pd.merge(merged, merged2, how = 'outer', on = ['timepoint', 'charge', 'start', 'end', 'temperature'])\n",
    "mergedc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new column for the max exchange value (NH_exchange_max) for each unique dataset - this value will be used in the fitting\n",
    "\n",
    "merged3 = {}\n",
    "merged3['NH_exchange_max'] = []\n",
    "merged3['start'] = []\n",
    "merged3['end'] = []\n",
    "merged3['charge'] = []\n",
    "merged3['temperature'] = []\n",
    "substt = ['charge', 'start', 'end', 'temperature']\n",
    "for add, adds in mergedc.groupby(by = substt):\n",
    "    tt = adds['avg'].max()\n",
    "    merged3['NH_exchange_max'].append(tt)\n",
    "    merged3['start'].append(adds['start'].iloc[0])\n",
    "    merged3['end'].append(adds['end'].iloc[0])\n",
    "    merged3['charge'].append(adds['charge'].iloc[0])\n",
    "    merged3['temperature'].append(adds['temperature'].iloc[0])\n",
    "merged3 = pd.DataFrame(merged3)\n",
    "\n",
    "\n",
    "WTmerged = pd.merge(mergedc, merged3, \n",
    "               how = 'outer', \n",
    "               on = ['charge', 'start', 'end', 'temperature'])\n",
    "\n",
    "WTmerged.to_csv('WTmerged.tsv', sep=\"\\t\")\n",
    "WTmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define equation for fitting (Exp3a) \n",
    "# define fitting and plotting parameters: plot errorbars based on SD, use plot(moreX...) to make a smooth line, return statement 'no fit' if data cannot be fit to the equation\n",
    "# define bounds and initial values when plotting\n",
    "\n",
    "def Exp3a(x, a, b, c, d, e, f, g):\n",
    "    return g-a*(np.exp(-d*x))-b*(np.exp(-e*x))-c*(np.exp(-f*x))\n",
    "\n",
    "def plotfit(df, x, y, yerr, hue, func, colors, p0, bounds):\n",
    "    for category, subset in df.groupby(by = [hue]):\n",
    "        X = subset[x].values\n",
    "        Y = subset[y].values\n",
    "        YR = subset[yerr].values\n",
    "        try:\n",
    "            popt, pcov = curve_fit(func, X, Y, p0=pinitial, bounds=bbounds)\n",
    "            moreX = np.arange(int(min(X)), int(max(X)), 0.001)       \n",
    "            plt.plot(moreX, func(moreX, *popt),\n",
    "                     label = ('T = %s' % \n",
    "                              (tempInfo[2])), \n",
    "                     color = colors[category])\n",
    "            plt.errorbar(X, Y, YR, fmt = 'none', ecolor='gray', elinewidth=1, capsize=3)\n",
    "            #plt.legend(bbox_to_anchor=(1.1, 1), loc=2, borderaxespad=0.)\n",
    "            sns.scatterplot(data = upepDF, \n",
    "                    x = 'timepoint', y = 'avg', hue = 'temperature', \n",
    "                    palette = temp2color, legend = False)\n",
    "        except RuntimeError:\n",
    "                print('no fit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot as Semi-log\n",
    "fitting to 3 exponentials\n",
    "''' \n",
    "\n",
    "groups2 = WTmerged.groupby(by = ['start', 'end', 'charge', 'sequence', 'NH-total'], as_index = False)\n",
    "num_groups = len(groups2)\n",
    "\n",
    "for upep, upepDF in tqdm(groups2, total = num_groups):\n",
    "    upepDF = upepDF.dropna(subset = ['avg'])\n",
    "    ylim = upepDF['NH-total'].iloc[0]\n",
    "\n",
    "    for tempInfo, tempDF in upepDF.groupby(by = ['start', 'end', 'temperature']):\n",
    "        start, end, temperature = tempInfo\n",
    "        Nobs = tempDF['NH_exchange_max'].iloc[0]\n",
    "        if Nobs == 0:\n",
    "            Nobs = 0.1\n",
    "        pinitial = Nobs*0.5, Nobs*0.5, Nobs*0.5, 5, 0.5, 0.01, Nobs\n",
    "        bbounds = ([0,0,0,2.5,0.05,0,Nobs*0.9],[Nobs*1.1,Nobs*1.1,Nobs*1.1,1000,2.5,0.05,Nobs*1.1])\n",
    " \n",
    "        plotfit(tempDF, x = 'timepoint', y = 'avg', yerr = 'sd', hue = 'temperature',\n",
    "                func = Exp3a, colors = temp2color, \n",
    "                p0 = pinitial, \n",
    "                bounds = bbounds)  \n",
    "\n",
    "    plt.xlabel('Time (min)')\n",
    "    plt.ylabel('Daltons')\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, ylim)\n",
    "    plt.xlim(0.1, 250)\n",
    "    \n",
    "#    sns.despine()\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.3, rc={\"lines.linewidth\": 2})\n",
    "    figname = 'SemiLog/%s-%s_c+%s.pdf' % (int(upep[0]), int(upep[1]), int(upep[2]))\n",
    "    plt.title('%s-%s_c+%s, %s amides' % (int(upep[0]), int(upep[1]), int(upep[2]), ylim))\n",
    "#    print(figname)\n",
    "    plt.savefig(figname, bbox_inches='tight')\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "# plt title gives peptide, charge, and number of reporting amides:\n",
    "# eg 2-23_c+3, 19 amides = peptide 2-23, +3 charge, with 19 amides\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot with x-axis linear\n",
    "'''        \n",
    "\n",
    "groups2 = WTmerged.groupby(by = ['start', 'end', 'charge', 'sequence', 'NH-total'], as_index = False)\n",
    "num_groups = len(groups2)\n",
    "\n",
    "for upep, upepDF in tqdm(groups2, total = num_groups):\n",
    "    upepDF = upepDF.dropna(subset = ['avg'])\n",
    "    ylim = upepDF['NH-total'].iloc[0]\n",
    "\n",
    "    for tempInfo, tempDF in upepDF.groupby(by = ['start', 'end', 'temperature']):\n",
    "        start, end, temperature = tempInfo\n",
    "        Nobs = tempDF['NH_exchange_max'].iloc[0]\n",
    "        if Nobs == 0:\n",
    "            Nobs = 0.1\n",
    "        pinitial = Nobs*0.5, Nobs*0.5, Nobs*0.5, 5, 0.5, 0.01, Nobs\n",
    "        bbounds = ([0,0,0,2.5,0.05,0,Nobs*0.9],[Nobs*1.1,Nobs*1.1,Nobs*1.1,1000,2.5,0.05,Nobs*1.1])\n",
    "\n",
    "        plotfit(tempDF, x = 'timepoint', y = 'avg', yerr = 'sd', hue = 'temperature',\n",
    "                func = Exp3a, colors = temp2color, \n",
    "                p0 = pinitial, \n",
    "                bounds = bbounds)  \n",
    "\n",
    "    plt.xlabel('Time (min)', fontsize=20)\n",
    "    plt.ylabel('Daltons', fontsize=20)\n",
    "    plt.xscale('linear')\n",
    "    plt.yscale('linear')\n",
    "    plt.ylim(0, ylim)\n",
    "    plt.xlim(-5, 250)\n",
    "    \n",
    "#    sns.despine()\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.3, rc={\"lines.linewidth\": 2})\n",
    "    figname = 'linear/%s-%s_c+%s.pdf' % (int(upep[0]), int(upep[1]), int(upep[2]))\n",
    "    plt.title('%s-%s_c+%s, %s amides' % (int(upep[0]), int(upep[1]), int(upep[2]), ylim))\n",
    "    print(figname)\n",
    "#    plt.savefig(figname, bbox_inches='tight')\n",
    "    plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining how to put all the fitted data in a table\n",
    "\n",
    "def fitdata(WTmerged, x, y, hue, func, colors, p0, bounds):\n",
    "    k2_df = []\n",
    "    k_df = {'variable':[], 'value':[], 'temperature':[], 'std.dev.res':[], 'DOF':[], 'Nobs':[]}\n",
    "    for category, subset in WTmerged.groupby(by = ['temperature']):\n",
    "        X = subset[x].values\n",
    "        Y = subset[y].values\n",
    "        try: \n",
    "            Nobs = subset['NH_exchange_max'].iloc[0]\n",
    "            if Nobs == 0:\n",
    "                Nobs = 0.1\n",
    "            pinitial = Nobs*0.5, Nobs*0.5, Nobs*0.5, 10, 0.5, 0.01, Nobs\n",
    "            bbounds = ([0,0,0,2.5,0.05,0,Nobs*0.9],[Nobs*1.1,Nobs*1.1,Nobs*1.1,1000,2.5,0.05,Nobs*1.1])\n",
    "            \n",
    "            popt, pcov = curve_fit(func, X, Y, p0 = pinitial, bounds = bbounds)\n",
    "            SDR = ((sum((Y - func(X, *popt))**2))/(len(Y)-len(p0)-2))**0.5\n",
    "\n",
    "            for variable, value in zip(['a', 'b', 'c', 'd', 'e', 'f', 'g'], popt):\n",
    "                k_df['variable'].append(variable)\n",
    "                k_df['value'].append(value)\n",
    "                k_df['temperature'].append(category)\n",
    "                k_df['std.dev.res'].append(SDR)\n",
    "                k_df['DOF'].append(len(Y)-len(p0)-1)\n",
    "                k_df['Nobs'].append(Nobs)\n",
    "\n",
    "        except RuntimeError:\n",
    "            for variable, value in zip(['a', 'b', 'c', 'd', 'e', 'f', 'g'], [np.nan]):\n",
    "                k_df['variable'].append(variable)\n",
    "                k_df['value'].append(value)\n",
    "                k_df['temperature'].append(category)\n",
    "                k_df['std.dev.res'].append(value)\n",
    "                k_df['DOF'].append(len(Y)-len(p0)-1)\n",
    "                k_df['Nobs'].append(Nobs)\n",
    "        k2_df.append(pd.DataFrame(k_df))\n",
    "    return pd.DataFrame(k_df)                                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the data in data table!\n",
    "                    \n",
    "  \n",
    "WTresults = []\n",
    "groups = WTmerged.groupby(by = ['sequence', 'charge', 'start', 'end'], as_index = False)\n",
    "num_groups = len(groups)\n",
    "for upep, upepDF in tqdm(groups, total = num_groups):\n",
    "    upepDF = upepDF.dropna(subset = ['Daltons'])  \n",
    "\n",
    "    results = fitdata(upepDF, x = 'timepoint', y = 'Daltons', hue = 'temperature',\n",
    "                          func = Exp3a, colors = temp2color, p0 = pinitial, bounds = bbounds)\n",
    "    results['sequence'] = [upep[0] for i in results['variable']]\n",
    "    results['charge'] = [upep[1] for i in results['variable']]\n",
    "    results['start'] = [upep[2] for i in results['variable']]\n",
    "    results['end'] = [upep[3] for i in results['variable']]\n",
    "    WTresults.append(results) \n",
    "\n",
    "WTresults = pd.concat(WTresults)\n",
    "WTresults.to_csv('WT_results.tsv', sep=\"\\t\")\n",
    "WTresults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the variable:value data and putting it into named individual columns\n",
    "\n",
    "subs = ['sequence', 'charge', 'start', 'end', 'temperature', 'std.dev.res']\n",
    "WTresults2 = {i:[] for i in subs}\n",
    "WTresults2['k1'] = []\n",
    "WTresults2['k2'] = []\n",
    "WTresults2['k3'] = []\n",
    "WTresults2['k1_NH'] = []\n",
    "WTresults2['k2_NH'] = []\n",
    "WTresults2['k3_NH'] = []\n",
    "WTresults2['Nobs_calc'] = []\n",
    "\n",
    "for pept, ResultsDF in WTresults.groupby(by = subs):\n",
    "    # store values to new dataframe\n",
    "    for sub, value in zip(subs, pept):\n",
    "        WTresults2[sub].append(value)\n",
    "    v = {variable:value for variable, value in zip(ResultsDF['variable'], ResultsDF['value'])}\n",
    "    WTresults2['k1'].append(v['d'])\n",
    "    WTresults2['k2'].append(v['e'])\n",
    "    WTresults2['k3'].append(v['f'])\n",
    "    WTresults2['k1_NH'].append(v['a'])\n",
    "    WTresults2['k2_NH'].append(v['b'])\n",
    "    WTresults2['k3_NH'].append(v['c'])    \n",
    "    WTresults2['Nobs_calc'].append(v['g'])  \n",
    "    \n",
    "WTresults2 = pd.DataFrame(WTresults2)\n",
    "WTresults2\n",
    "\n",
    "# combine merged and results tables\n",
    "\n",
    "WTresults3 = pd.merge(WTresults2, WTmerged, \n",
    "               how = 'outer', \n",
    "               on = ['sequence', 'charge', 'start', 'end', 'temperature',])\n",
    "WTresults3.sort_values(by=['start', 'end', 'charge', 'temperature', 'timepoint'])\n",
    "\n",
    "WT_minimal = WTresults3.drop(columns = ['percentD', 'timepoint','valid','percentD_good', 'percentD_corr', 'BE', 'replicate',])\n",
    "WT_minimal = WT_minimal.drop_duplicates()\n",
    "WT_minimal = WT_minimal.sort_values(['start','end','charge','temperature'])\n",
    "WT_minimal.to_csv('WT_minimal.tsv', sep=\"\\t\")\n",
    "WT_minimal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " '''modify WT_minimal --> \n",
    "    strip C from temperature and make it an integer\n",
    "    make new column for 1/T(K)\n",
    "    make new column for ln()\n",
    "    math.log(x) = natural logarithm of x\n",
    "'''   \n",
    "\n",
    "def func_invT(x):\n",
    "    return 1000/(273.15+x)\n",
    "def func_lnk(x):\n",
    "    try:\n",
    "        return math.log(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "WT_minimal2 = WT_minimal.drop(columns = ['std.dev.res', 'Daltons', 'sd', 'avg'])\n",
    "WT_minimal2['temp. degrees'] = [int(i.replace('C','')) for i in WT_minimal2['temperature']]\n",
    "WT_minimal2['1000/T (K)'] = func_invT(WT_minimal2['temp. degrees'])\n",
    "WT_minimal2['ln(p2*k2+p3*k3)_NHtotal'] = [func_lnk(i) for i in ((WT_minimal2['k2']*WT_minimal2['k2_NH']+WT_minimal2['k3']*WT_minimal2['k3_NH'])/WT_minimal2['NH-total'])]\n",
    "WT_minimal2 = WT_minimal2.drop_duplicates()\n",
    "WT_minimal2.to_csv('WT_minimal2.tsv', sep=\"\\t\")\n",
    "WT_minimal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining linear regression calculation for Ea(HDX) and plotting\n",
    "# Plot each graph and put Ea and SE values in legend\n",
    "\n",
    "def linfit(df, x, y, color):\n",
    "    \n",
    "    Ea_df = {'slope':[], 'Ea':[], 'r^2':[], 'SE':[]}\n",
    "    X = df[x].values\n",
    "    Y = df[y].values\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X,Y)\n",
    "    R = 1.987\n",
    "    Ea = float(-slope*R)\n",
    "    r2 = float(r_value**2)\n",
    "    SE_R = float(std_err*R)\n",
    "    plt.plot(X, intercept + slope*X, 'r', label=('Ea = %2.1f, SE = %2.1f' % (Ea, SE_R)), color = color )\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlim(3.13,3.6)\n",
    "    plt.xlabel('1000/T (1/K)')\n",
    "    plt.ylabel('ln(kHDX)')\n",
    "    Ea_df['slope'].append(slope)\n",
    "    Ea_df['Ea'].append(Ea)\n",
    "    Ea_df['r^2'].append(r2)\n",
    "    Ea_df['SE'].append(SE_R)\n",
    "        \n",
    "    return pd.DataFrame(Ea_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "for set1, setDF in WT_minimal2.groupby(by = ['start','end','charge']):\n",
    "    start, end, charge = set1\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.scatterplot(data = setDF, x='1000/T (K)',y='ln(p2*k2+p3*k3)_NHtotal', hue='temperature', palette = temp2colorblack, legend = False, label = 'ln(p2*k2+p3*k3)')\n",
    "    Ea1_temp = linfit(setDF, x = '1000/T (K)', y = 'ln(p2*k2+p3*k3)_NHtotal', color = 'black')\n",
    "    sns.set_style(\"ticks\")    \n",
    "    figname1 = 'WT_Ea/%s-%s_c+%s_n_Ea.pdf' % (int(set1[0]), int(set1[1]), int(set1[2]))\n",
    "    plt.title('%s-%s_c+%s, %s amides' % (int(set1[0]), int(set1[1]), int(set1[2]), ylim))\n",
    "    plt.savefig(figname1, bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
